{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0f14817d-c681-41d2-b055-f043d2b38cd3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f14817d-c681-41d2-b055-f043d2b38cd3",
        "outputId": "fb58854b-941d-4edf-f812-9019eed14dc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the 'word2vec-google-news-300' model... (This may take a while)\n",
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "Model loaded successfully!\n",
            "\n",
            "==================================================\n",
            "Part 1: Finding Similar Words\n",
            "==================================================\n",
            "\n",
            "--- Words most similar to 'galaxy' ---\n",
            "galaxies             Similarity: 0.7880\n",
            "Milky_Way_galaxy     Similarity: 0.7715\n",
            "Milky_Way_Galaxy     Similarity: 0.7398\n",
            "Milky_Way            Similarity: 0.7311\n",
            "distant_galaxy       Similarity: 0.7264\n",
            "\n",
            "--- Words most similar to 'keyboard' ---\n",
            "keyboards            Similarity: 0.7883\n",
            "Keyboard             Similarity: 0.7165\n",
            "touchpad             Similarity: 0.7083\n",
            "trackpad             Similarity: 0.7040\n",
            "keypad               Similarity: 0.6944\n",
            "\n",
            "--- Words most similar to 'music' ---\n",
            "classical_music      Similarity: 0.7198\n",
            "jazz                 Similarity: 0.6835\n",
            "Music                Similarity: 0.6596\n",
            "Without_Donny_Kirshner Similarity: 0.6416\n",
            "songs                Similarity: 0.6396\n",
            "\n",
            "--- Words most similar to 'running' ---\n",
            "Running              Similarity: 0.6979\n",
            "ran                  Similarity: 0.6085\n",
            "run                  Similarity: 0.6063\n",
            "runnning             Similarity: 0.5533\n",
            "runing               Similarity: 0.5427\n",
            "\n",
            "--- Words most similar to 'happy' ---\n",
            "glad                 Similarity: 0.7409\n",
            "pleased              Similarity: 0.6632\n",
            "ecstatic             Similarity: 0.6627\n",
            "overjoyed            Similarity: 0.6599\n",
            "thrilled             Similarity: 0.6514\n",
            "\n",
            "==================================================\n",
            "Part 2: Word Analogy Experiments\n",
            "==================================================\n",
            "\n",
            "--- Analogy 1: king - man + woman ~= ? ---\n",
            "Result: queen (Similarity: 0.7118)\n",
            "Observation: The model correctly identifies 'queen' as the answer.\n",
            "\n",
            "--- Analogy 2: France - Paris + Berlin ~= ? ---\n",
            "Result: Germany (Similarity: 0.7901)\n",
            "Observation: The model successfully finds 'Germany', capturing the country-capital relationship.\n",
            "\n",
            "--- Analogy 3: walking - walk + swim ~= ? ---\n",
            "Result: swimming (Similarity: 0.8246)\n",
            "Observation: The model understands grammatical relationships, correctly identifying 'swimming'.\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# --- Step 1: Load the pre-trained Word2Vec model ---\n",
        "# This will download the model (approx. 1.6 GB) on the first run.\n",
        "# Subsequent runs will load it from the local cache.\n",
        "print(\"Loading the 'word2vec-google-news-300' model... (This may take a while)\")\n",
        "try:\n",
        "    model = api.load('word2vec-google-news-300')\n",
        "    print(\"Model loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load model. Error: {e}\")\n",
        "    print(\"Please check your internet connection or try again later.\")\n",
        "    exit()\n",
        "\n",
        "# The loaded model contains word vectors, but not the full training model.\n",
        "# For our purposes, this is exactly what we need.\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Part 1: Finding Similar Words\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# --- Step 2: Pick 5 words and find their most similar words ---\n",
        "words_to_check = ['galaxy', 'keyboard', 'music', 'running', 'happy']\n",
        "\n",
        "for word in words_to_check:\n",
        "    print(f\"\\n--- Words most similar to '{word}' ---\")\n",
        "    try:\n",
        "        # The most_similar() function finds the top-N most similar words.\n",
        "        # It returns a list of tuples, where each tuple is (word, similarity_score).\n",
        "        similar_words = model.most_similar(word, topn=5)\n",
        "        for similar_word, score in similar_words:\n",
        "            print(f\"{similar_word:<20} Similarity: {score:.4f}\")\n",
        "    except KeyError:\n",
        "        # This happens if the word is not in the model's vocabulary.\n",
        "        print(f\"Sorry, the word '{word}' is not in the vocabulary.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Part 2: Word Analogy Experiments\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# --- Step 3: Perform word analogy tests ---\n",
        "# The logic is: vector(A) - vector(B) + vector(C) should be close to vector(D)\n",
        "# where the relationship is \"B is to A as C is to D\".\n",
        "# The most_similar function handles this with `positive` and `negative` parameters.\n",
        "# D = most_similar(positive=[A, C], negative=[B])\n",
        "\n",
        "# Analogy 1: The classic \"King - Man + Woman\"\n",
        "print(\"\\n--- Analogy 1: king - man + woman ~= ? ---\")\n",
        "# Expected result: queen\n",
        "try:\n",
        "    result = model.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n",
        "    print(f\"Result: {result[0][0]} (Similarity: {result[0][1]:.4f})\")\n",
        "    print(\"Observation: The model correctly identifies 'queen' as the answer.\")\n",
        "except KeyError as e:\n",
        "    print(f\"A word in the analogy was not found in the vocabulary: {e}\")\n",
        "\n",
        "# Analogy 2: Country-Capital Relationship \"France - Paris + Berlin\"\n",
        "# This is a bit backward. The correct analogy is \"Paris is to France as Berlin is to ?\"\n",
        "# So, Germany = France - Paris + Berlin\n",
        "print(\"\\n--- Analogy 2: France - Paris + Berlin ~= ? ---\")\n",
        "# Expected result: Germany\n",
        "try:\n",
        "    # We are asking: \"What country is Berlin the capital of, in the same way Paris is the capital of France?\"\n",
        "    result = model.most_similar(positive=['France', 'Berlin'], negative=['Paris'], topn=1)\n",
        "    print(f\"Result: {result[0][0]} (Similarity: {result[0][1]:.4f})\")\n",
        "    print(\"Observation: The model successfully finds 'Germany', capturing the country-capital relationship.\")\n",
        "except KeyError as e:\n",
        "    print(f\"A word in the analogy was not found in the vocabulary: {e}\")\n",
        "\n",
        "# Analogy 3: Verb Tense Relationship \"walking - walk + swim\"\n",
        "# Analogy: \"walk is to walking as swim is to ?\"\n",
        "print(\"\\n--- Analogy 3: walking - walk + swim ~= ? ---\")\n",
        "# Expected result: swimming\n",
        "try:\n",
        "    # We are asking: \"What is the present participle of 'swim', in the same way 'walking' is for 'walk'?\"\n",
        "    result = model.most_similar(positive=['walking', 'swim'], negative=['walk'], topn=1)\n",
        "    print(f\"Result: {result[0][0]} (Similarity: {result[0][1]:.4f})\")\n",
        "    print(\"Observation: The model understands grammatical relationships, correctly identifying 'swimming'.\")\n",
        "except KeyError as e:\n",
        "    print(f\"A word in the analogy was not found in the vocabulary: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ab6ba3b4-5528-4e5e-8d2b-62a109ce329d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab6ba3b4-5528-4e5e-8d2b-62a109ce329d",
        "outputId": "ae40e09a-d8ea-480f-bc83-411e4c7a6e6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5c75e37-e96f-4c66-9ccf-4926f3540478",
      "metadata": {
        "id": "b5c75e37-e96f-4c66-9ccf-4926f3540478"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}